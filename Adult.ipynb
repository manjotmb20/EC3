{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled152.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMEcvp7K6YiTwGvFP4RVpHn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manjotmb20/EC3/blob/master/Adult.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFyOyPRxTfdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59c85a7c-c4e4-4aeb-edc7-380b1081b3ce"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn import preprocessing\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "\n",
        "df=pd.read_csv(\"adult.csv\")\n",
        "df.dropna(inplace=True)\n",
        "len(df)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj-iW2nRYXSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category_col =['workclass', 'race', 'education','marital-status', 'occupation',\n",
        "               'relationship', 'sex', 'native-country', 'income'] \n",
        "labelEncoder = preprocessing.LabelEncoder()\n",
        "for col in category_col:\n",
        "    df[col] = labelEncoder.fit_transform(df[col])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECpgNBShUKpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "5a82a462-011e-44f3-cbe2-a446c025562a"
      },
      "source": [
        "X = df.values[:, :14]\n",
        "y = df.values[:,14]\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, y)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train=sc.fit_transform(x_train)\n",
        "X_test = sc.transform(x_val)\n",
        "classifier=LogisticRegression(C=5.0,random_state=0)\n",
        "classifier.fit(x_train,y_train)\n",
        "ypred=classifier.predict(x_val)\n",
        "print(\"Accuracy score of LR\",accuracy_score(y_val,ypred))\n",
        "y_prob=classifier.predict_proba(x_val)\n",
        "df=pd.DataFrame()\n",
        "df['pred']=ypred\n",
        "survived=pd.get_dummies(df.pred,prefix='Survived')\n",
        "df=pd.concat([df,survived],axis=1)\n",
        "df.drop('pred',inplace=True,axis=1)\n",
        "df2=pd.DataFrame()\n",
        "classifier3=DecisionTreeClassifier()\n",
        "classifier3.fit(x_train,y_train)\n",
        "ypred3=classifier3.predict(x_val)\n",
        "print(\"Accuracy score of Decision Tree\",accuracy_score(y_val,ypred3))\n",
        "df2['pred']=ypred3\n",
        "y_prob3=classifier3.predict_proba(x_val)\n",
        "survived2=pd.get_dummies(df2.pred,prefix='Surviveds')\n",
        "df=pd.concat([df,survived2],axis=1)\n",
        "df"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score of LR 0.8056133056133056\n",
            "Accuracy score of Decision Tree 0.9573804573804574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived_0</th>\n",
              "      <th>Survived_1</th>\n",
              "      <th>Surviveds_0</th>\n",
              "      <th>Surviveds_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>959</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>960</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>961</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>962 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived_0  Survived_1  Surviveds_0  Surviveds_1\n",
              "0             0           1            0            1\n",
              "1             0           1            0            1\n",
              "2             0           1            0            1\n",
              "3             0           1            0            1\n",
              "4             1           0            1            0\n",
              "..          ...         ...          ...          ...\n",
              "957           0           1            0            1\n",
              "958           0           1            0            1\n",
              "959           1           0            1            0\n",
              "960           0           1            0            1\n",
              "961           0           1            1            0\n",
              "\n",
              "[962 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH8SO53QU4GK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m=np.array(df)\n",
        "s=np.zeros(shape=(m.shape[0],m.shape[0]))\n",
        "for i in range(m.shape[0]):\n",
        "  for j in range(m.shape[0]):\n",
        "    if i!=j:\n",
        "      sum1=0\n",
        "      for k in range(2,m.shape[1]):\n",
        "        sum1=sum1+(m[i][k]*m[j][k])\n",
        "      s[i][j]=sum1\n",
        "w=s\n",
        "d=np.zeros(shape=w.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG-izjB6bIYS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7ac4f16e-7a86-4f6e-fcab-abf534015f1d"
      },
      "source": [
        "for i in range(d.shape[0]):\n",
        "  d[i]=np.sum(w[i],axis=0)\n",
        "wnew=w/d.reshape(d.shape[0],1)\n",
        "Km=wnew\n",
        "Km\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.00167224, 0.00167224, ..., 0.        , 0.00167224,\n",
              "        0.        ],\n",
              "       [0.00167224, 0.        , 0.00167224, ..., 0.        , 0.00167224,\n",
              "        0.        ],\n",
              "       [0.00167224, 0.00167224, 0.        , ..., 0.        , 0.00167224,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.00276243],\n",
              "       [0.00167224, 0.00167224, 0.00167224, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.00276243, 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y5Os1YObN9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d87fbac4-a30f-4d95-eee5-d2a9b352d94e"
      },
      "source": [
        "print(np.sum(Km,axis=1))\n",
        "print(np.sum(Km,axis=0))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1.]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1V-98pImkVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "m=m.dot(m.T)  \n",
        "s=np.zeros(shape=(m.shape[0],m.shape[0]))\n",
        "for i in range(m.shape[0]):\n",
        "  for j in range(m.shape[0]):\n",
        "    if i!=j:\n",
        "      sum1=0\n",
        "      for k in range(2,m.shape[1]):\n",
        "        sum1=sum1+(m[i][k]*m[j][k])\n",
        "      s[i][j]=sum1   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j40zOKQ-mnOz",
        "colab_type": "code",
        "outputId": "27f75eca-bfdf-42cd-f186-ad491b8d6f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "d=np.zeros(shape=w.shape[0])\n",
        "w=s\n",
        "for i in range(d.shape[0]):\n",
        "  d[i]=np.sum(w[i],axis=0)\n",
        "wnew=w/d.reshape(d.shape[0],1)  \n",
        "Kc=wnew\n",
        "Kc"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.00159626, 0.00159626, ..., 0.00013716, 0.00159626,\n",
              "        0.00086233],\n",
              "       [0.00159626, 0.        , 0.00159626, ..., 0.00013716, 0.00159626,\n",
              "        0.00086233],\n",
              "       [0.00159626, 0.00159626, 0.        , ..., 0.00013716, 0.00159626,\n",
              "        0.00086233],\n",
              "       ...,\n",
              "       [0.00032536, 0.00032536, 0.00032536, ..., 0.        , 0.00032536,\n",
              "        0.00125644],\n",
              "       [0.00159626, 0.00159626, 0.00159626, ..., 0.00013716, 0.        ,\n",
              "        0.00086233],\n",
              "       [0.00122112, 0.00122112, 0.00122112, ..., 0.00075003, 0.00122112,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAFnKTDscdnX",
        "colab_type": "text"
      },
      "source": [
        "**Same, checking for bi-stochastic behaviour**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlvTfnrF2Smi",
        "colab_type": "code",
        "outputId": "d6fc24bb-a420-4e80-8a80-13506afbe222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "  np.sum(Kc,axis=1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmJ1FML0ckLi",
        "colab_type": "text"
      },
      "source": [
        "**Generating Fg and Fo i'e the Group class matrix and Object Class matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTO5d9Ay2Xc5",
        "colab_type": "code",
        "outputId": "1a210a8c-74f2-4e55-fd83-3eef07c881e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\n",
        "objclass_mat1=pd.DataFrame(y_prob,columns=['Survived','NotSurvived'])\n",
        "objclass_mat2=pd.DataFrame(y_prob3,columns=['Survived','NotSurvived'])\n",
        "df_t=pd.DataFrame(objclass_mat1)\n",
        "Fo=np.array(df_t)\n",
        "gpclass_mat=pd.DataFrame(columns=['Survived','NotSurvived'],index=['class1surv','class1notsurv','class2surv','class2notsurv'])\n",
        "prob1s=np.sum(objclass_mat1.Survived)/len(objclass_mat1)\n",
        "prob1ns=np.sum(objclass_mat1.NotSurvived)/len(objclass_mat1)\n",
        "prob2s=np.sum(objclass_mat2.Survived)/len(objclass_mat2)\n",
        "prob2ns=np.sum(objclass_mat2.NotSurvived)/len(objclass_mat2)\n",
        "list1=[]\n",
        "list1.append(prob1s)\n",
        "list1.append(prob1ns)\n",
        "list1.append(prob2s)\n",
        "list1.append(prob2ns)\n",
        "\n",
        "list2=[]\n",
        "list2.append(prob1ns)\n",
        "list2.append(prob1s)\n",
        "list2.append(prob2ns)\n",
        "list2.append(prob2s)\n",
        "gpclass_mat['Survived']=list1\n",
        "gpclass_mat['NotSurvived']=list2\n",
        "gpclass_mat\n",
        "Fg=np.array(gpclass_mat)\n",
        "Fg"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.38290849, 0.61709151],\n",
              "       [0.61709151, 0.38290849],\n",
              "       [0.37733888, 0.62266112],\n",
              "       [0.62266112, 0.37733888]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRxO_k8tct-4",
        "colab_type": "text"
      },
      "source": [
        "**Similarly, generating  Yo and Yg**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovw7WJ7S2pQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n=2\n",
        "C=survived.shape[1]\n",
        "G=survived.shape[1]*n\n",
        "\n",
        "Yo=np.zeros(shape=(df.shape[0],C))\n",
        "cal_y=np.array(df)\n",
        "for i in range(Yo.shape[0]):\n",
        "  Yo[i][0]=(cal_y[i][0]+cal_y[i][2])/C\n",
        "for i in range(Yo.shape[0]):\n",
        "  Yo[i][1]=(cal_y[i][1]+cal_y[i][3])/C"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SR3KDg3q87U",
        "colab_type": "code",
        "outputId": "bf49d056-90f0-4fc1-b9f1-4756678c2ffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "G"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYZkiSfs2w2I",
        "colab_type": "code",
        "outputId": "e7b32840-a7ac-41ea-881a-76cf6c45d19a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "m=np.array(df)\n",
        "Yg=np.zeros(shape=(m.shape[1],2))\n",
        "c=np.sum(m,axis=0)\n",
        "for i in range(Yg.shape[0]):\n",
        "  if i%2==0:\n",
        "    Yg[i][0]=c[i]/m.shape[0]\n",
        "    Yg[i][1]=1-Yg[i][0]\n",
        "  else:\n",
        "    Yg[i][1]=c[i]/m.shape[0]\n",
        "    Yg[i][0]=1-Yg[i][1]  \n",
        "Yg"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.38357588, 0.61642412],\n",
              "       [0.38357588, 0.61642412],\n",
              "       [0.37733888, 0.62266112],\n",
              "       [0.37733888, 0.62266112]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTa6_2DsdIlO",
        "colab_type": "text"
      },
      "source": [
        "Genearting "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hcY4DpgduI4",
        "colab_type": "text"
      },
      "source": [
        "Checking for the conditions specified in eq 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHAljZHU21jH",
        "colab_type": "code",
        "outputId": "540d7e59-f2da-4e4c-b3eb-3ce5d4560b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "Fo_cond=True\n",
        "Fg_cond=True\n",
        "for i in range(Fo.shape[0]):\n",
        "  if np.linalg.norm((Fo[i]), ord=1)!=1:\n",
        "    Fo_cond=False\n",
        "for i in range(Fg.shape[0]):\n",
        "  if np.linalg.norm((Fg[i]), ord=1)!=1:\n",
        "    Fo_cond=False    \n",
        "print(Fo_cond)\n",
        "print(Fg_cond)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7YlgtdbeCFc",
        "colab_type": "text"
      },
      "source": [
        "**Generating diagonal matrices Dm and Dc**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8cG1naJ3Cbk",
        "colab_type": "code",
        "outputId": "de8051a5-7be7-4f8f-80aa-86311cad56c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_dm=np.zeros(shape=(Km.shape))\n",
        "test_Km=Km\n",
        "for i in range(test_Km.shape[0]):\n",
        "  test_dm[i]=np.sum(test_Km[i],axis=0)\n",
        "Dm=np.diag(np.diag(test_dm))\n",
        "print(\"Shape of DM\",Dm.shape)\n",
        "test_dc=np.zeros(shape=(Kc.shape))\n",
        "test_Kc=Kc\n",
        "for i in range(test_Kc.shape[0]):\n",
        "  test_dc[i]=np.sum(test_Kc[i],axis=0)\n",
        "Dc=np.diag(np.diag(test_dc))\n",
        "print(\"shape of Dc\",Dc.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of DM (962, 962)\n",
            "shape of Dc (962, 962)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv1sYezy3Hwa",
        "colab_type": "code",
        "outputId": "833c8ad4-4d56-4534-fd3d-dceb05198e21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(\"KHM\",Km.shape)\n",
        "print(\"KHC\",Kc.shape)\n",
        "print(\"Fo\",Fo.shape)\n",
        "print(\"Fg\",Fg.shape)\n",
        "print(\"Yo\",Yo.shape)\n",
        "print(\"Yg\",Yg.shape)\n",
        "print(\"Dm\",Dm.shape)\n",
        "print(\"Dc\",Dc.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KHM (962, 962)\n",
            "KHC (962, 962)\n",
            "Fo (962, 2)\n",
            "Fg (4, 2)\n",
            "Yo (962, 2)\n",
            "Yg (4, 2)\n",
            "Dm (962, 962)\n",
            "Dc (962, 962)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCBI0yrwqzOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5InaYBP3Lfq",
        "colab_type": "code",
        "outputId": "dec2403b-52ab-4248-a419-32f542148acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "Yg=np.pad(Yg,pad_width=[(0, Km.shape[0]-G), (0, 0)])\n",
        "Yg.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(962, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro1G66qS5Pzv",
        "colab_type": "code",
        "outputId": "4c79c4aa-e960-4bf8-97c8-029ca5769ee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(\"KHM\",Km.shape)\n",
        "print(\"KHC\",Kc.shape)\n",
        "print(\"Fo\",Fo.shape)\n",
        "print(\"Fg\",Fg.shape)\n",
        "print(\"Yo\",Yo.shape)\n",
        "print(\"Yg\",Yg.shape)\n",
        "print(\"Dm\",Dm.shape)\n",
        "print(\"Dc\",Dc.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KHM (962, 962)\n",
            "KHC (962, 962)\n",
            "Fo (962, 2)\n",
            "Fg (4, 2)\n",
            "Yo (962, 2)\n",
            "Yg (962, 2)\n",
            "Dm (962, 962)\n",
            "Dc (962, 962)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OVQOQf35Tb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "threshold=sys.float_info.epsilon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2yQviy9gmJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import linalg as LA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTILUgDfeX91",
        "colab_type": "text"
      },
      "source": [
        "**Implementing algorithm 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaOULbFt5XBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha=0.25\n",
        "beta=0.35\n",
        "gamma=0.35\n",
        "delta=0.05\n",
        "Fo_t=np.zeros(shape=Fo.shape)\n",
        "Fg_t=np.zeros(shape=Fg.shape)\n",
        "Fot_old=np.zeros(shape=Fo.shape)\n",
        "Fo_t=Fo\n",
        "Fg_t=Fg\n",
        "while LA.norm((Fo_t-Fot_old),'fro')>threshold:\n",
        "  Fot_old=Fo_t\n",
        "  Fg_t=np.matmul((np.linalg.inv(2*delta*np.ones(shape=Dm.shape)+(alpha*Dm))),((alpha*np.matmul(Km,Fo_t))+(2*delta*Yg)))\n",
        "  Fo_t=np.matmul((np.linalg.inv((alpha*Dm)+(2*beta*Dc)-(beta*np.matmul(np.identity(Kc.shape[0]),Kc))-(beta*np.matmul(np.ones(shape=Kc.shape),Kc))+(2*gamma*np.identity(Kc.shape[0])))),((alpha*np.matmul(Km,Fg_t))+(2*gamma*Yo)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhH4nVo_5e6_",
        "colab_type": "code",
        "outputId": "70393647-d182-4c09-e066-699bae22147d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score,roc_auc_score\n",
        "result=np.zeros(shape=Fo_t.shape[0])\n",
        "for i in range(Fo_t.shape[0]):\n",
        "  if Fo_t[i][0]<Fo_t[i][1]:\n",
        "    result[i]=1\n",
        "print(\"Accuracy value for Ensemble model\",accuracy_score(y_val,result))\n",
        "print(\"AUC for for Ensemble model\",roc_auc_score(y_val,result))\n",
        "print(\"Accuracy value for LR\",accuracy_score(y_val,ypred))\n",
        "print(\"AUC for for LR\",roc_auc_score(y_val,ypred))\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy value for Ensemble model 0.8835758835758836\n",
            "AUC for for Ensemble model 0.8977652312831311\n",
            "Accuracy value for LR 0.8056133056133056\n",
            "AUC for for LR 0.7942188294241523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUskNBtfe5C7",
        "colab_type": "text"
      },
      "source": [
        "**We see that the ensemble model performs better than the Random forest, Kneigbours and Svm models and is at par with the Logistic regression model that gives us the best accuracy. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-wv5VdjiJm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}